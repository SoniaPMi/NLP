{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoniaPMi/NLP/blob/main/NLP_04_Introducci%C3%B3n_al_spaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXUcUrZZmLlT"
      },
      "source": [
        "# Introducción a la librería spaCy\n",
        "En este *notebook* vamos a describir el uso de la librería `spaCy` para el Procesado de Lenguaje Natural."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9uewTD5kmLlX"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy==2.2.4\n",
        "!python -m spacy download es_core_news_sm\n",
        "!python -m spacy download en_core_web_md\n",
        "!python -m spacy download es_core_news_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H4Dls4Lmyi0",
        "outputId": "58796eb7-88fd-4958-afe1-017167422640"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy==2.2.4 in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (4.64.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.21.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (3.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (0.9.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (1.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4) (2.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4) (2021.10.8)\n",
            "Collecting es_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz (16.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.2 MB 18.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n",
            "Collecting en_core_web_md==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "Collecting es_core_news_md==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-2.2.5/es_core_news_md-2.2.5.tar.gz (78.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 78.4 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from es_core_news_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_md==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_md==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_md==2.2.5) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_md==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_md==2.2.5) (3.0.4)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a1i9qp4mLlZ"
      },
      "source": [
        "Cargamos la librería y el modelo de lenguaje para el español. Vemos las principales características de la librería y del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2WMVaU6mLla",
        "outputId": "c765199b-8b10-4d45-ebf2-2e9d57bc1af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    2.2.4                         \n",
            "Location         /usr/local/lib/python3.7/dist-packages/spacy\n",
            "Platform         Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Python version   3.7.13                        \n",
            "Models           en                            \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Location': '/usr/local/lib/python3.7/dist-packages/spacy',\n",
              " 'Models': 'en',\n",
              " 'Platform': 'Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic',\n",
              " 'Python version': '3.7.13',\n",
              " 'spaCy version': '2.2.4'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "spacy.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-nnTLwfmLlb"
      },
      "source": [
        "Comprobamos los modelos de lenguaje instalados (compatible con todas las versiones de `spaCy`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC4D6e8lmLlc",
        "outputId": "5b8644de-fb0c-4528-8d8c-91ca39547d80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r⠙ Loading compatibility table...\r\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
            "\u001b[1m\n",
            "====================== Installed models (spaCy v2.2.4) ======================\u001b[0m\n",
            "\u001b[38;5;4mℹ spaCy installation: /usr/local/lib/python3.7/dist-packages/spacy\u001b[0m\n",
            "\n",
            "TYPE      NAME              MODEL             VERSION                            \n",
            "package   es-core-news-sm   es_core_news_sm   \u001b[38;5;2m2.2.5\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "package   es-core-news-md   es_core_news_md   \u001b[38;5;2m2.2.5\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "package   en-core-web-sm    en_core_web_sm    \u001b[38;5;2m2.2.5\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "package   en-core-web-md    en_core_web_md    \u001b[38;5;2m2.2.5\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "link      en                en_core_web_sm    \u001b[38;5;2m2.2.5\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-AD3Y87KmLlc"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"es_core_news_md\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v169XuY1mLld"
      },
      "source": [
        "## Arquitectura del modelo\n",
        "Para cada modelo, `spaCy` tiene un vocabulario de palabras conocidas (*lexemes*) que almacena en un `stringStore` global"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v9mrUKMmLle"
      },
      "source": [
        "Cada modelo tiene un conjunto de lexemas del idioma definidos en su Vocabulario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SLZcWVamLle",
        "outputId": "95199066-44e2-4d6f-edb4-6b9c879ff4ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.vocab.Vocab at 0x7efe5a78fc20>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "nlp.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09P7oZ_OmLlf",
        "outputId": "b5b916ea-2c34-4684-b8c5-5b45cba55f85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1229970"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(nlp.vocab) #esta longitud es falsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmAb1ySGmLlg",
        "outputId": "457f6649-c506-45a8-f7b1-259b88411340"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1632081"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(nlp.vocab.strings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyl6ycqfmLlg",
        "outputId": "e919514b-9378-4ade-8bef-28b258afc1e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lexeme.Lexeme at 0x7efe4113a870>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "nlp.vocab[\"ciudad\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EFi1qT5rmLlh",
        "outputId": "65e2ee84-b77c-4cdb-d356-2bd624c073e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ciudad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "nlp.vocab[\"ciudad\"].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8VCHE8xmLlh",
        "outputId": "69e7cc1e-878e-468c-8b30-3cb363a5bd97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['check_flag',\n",
              " 'cluster',\n",
              " 'flags',\n",
              " 'from_bytes',\n",
              " 'has_vector',\n",
              " 'is_alpha',\n",
              " 'is_ascii',\n",
              " 'is_bracket',\n",
              " 'is_currency',\n",
              " 'is_digit',\n",
              " 'is_left_punct',\n",
              " 'is_lower',\n",
              " 'is_oov',\n",
              " 'is_punct',\n",
              " 'is_quote',\n",
              " 'is_right_punct',\n",
              " 'is_space',\n",
              " 'is_stop',\n",
              " 'is_title',\n",
              " 'is_upper',\n",
              " 'lang',\n",
              " 'lang_',\n",
              " 'like_email',\n",
              " 'like_num',\n",
              " 'like_url',\n",
              " 'lower',\n",
              " 'lower_',\n",
              " 'norm',\n",
              " 'norm_',\n",
              " 'orth',\n",
              " 'orth_',\n",
              " 'prefix',\n",
              " 'prefix_',\n",
              " 'prob',\n",
              " 'rank',\n",
              " 'sentiment',\n",
              " 'set_attrs',\n",
              " 'set_flag',\n",
              " 'shape',\n",
              " 'shape_',\n",
              " 'similarity',\n",
              " 'suffix',\n",
              " 'suffix_',\n",
              " 'text',\n",
              " 'to_bytes',\n",
              " 'vector',\n",
              " 'vector_norm',\n",
              " 'vocab']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "[prop for prop in dir(spacy.lexeme.Lexeme) if not prop.startswith('_')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_dCSWLgmLli",
        "outputId": "b50f2be7-8010-4668-dcfa-087f513b65d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "nlp.vocab[\"adiós\"].has_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko0CIEjkmLlj",
        "outputId": "daf5912d-20d6-4fde-bad3-af3de8dfb718"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "\"albaricoque\" in nlp.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1RDjVZ6mLlj",
        "outputId": "e9222a9b-a17d-4657-ae6f-4d89e4aa8340"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lexeme.Lexeme at 0x7efe59ea45f0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "nlp.vocab[\"albaricoque\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBRH-FpPmLlk",
        "outputId": "62286052-5ab9-4237-ae7c-1df59529827b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "\"albaricoque\" in nlp.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I3gWUKQmLll",
        "outputId": "42fd42ed-a995-4826-806c-7f221e626ad2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15970597814306712899"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "nlp.vocab[\"adiós\"].orth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "za2mGMbjmLlm",
        "outputId": "b29651cb-95ab-4f69-95b6-a044fa514752"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'adiós'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "nlp.vocab.strings[15970597814306712899]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmirf9-BmLln"
      },
      "source": [
        "## Procesado de texto\n",
        "spaCy ejecuta todos los análisis del texto con una sola instrucción. Esta instrucción ejecuta un *pipeline* (procesado secuencial) que implementa:  \n",
        "\n",
        "- División en tokens  \n",
        "- Lematizado\n",
        "- Análisis gramatical\n",
        "- Análisis de dependencias\n",
        "- *Name Entity Recognition* (NER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-tXnPC_fmLln"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de texto\n",
        "texto = \"La gata de Juan es muy bonita.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkYrvE1ZmLlo"
      },
      "source": [
        "Lo primero que hacemos es procesar el texto y generar un objeto de tipo `Doc`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncqtN-j7mLlo",
        "outputId": "e190d3d4-5410-446f-d98c-812304481f8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "doc = nlp(texto)\n",
        "type(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxsfWlrQmLlp",
        "outputId": "2da1c74f-5208-4681-e4e8-01cab8554ac4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cats',\n",
              " 'char_span',\n",
              " 'count_by',\n",
              " 'doc',\n",
              " 'ents',\n",
              " 'extend_tensor',\n",
              " 'from_array',\n",
              " 'from_bytes',\n",
              " 'from_disk',\n",
              " 'get_extension',\n",
              " 'get_lca_matrix',\n",
              " 'has_extension',\n",
              " 'has_vector',\n",
              " 'is_nered',\n",
              " 'is_parsed',\n",
              " 'is_sentenced',\n",
              " 'is_tagged',\n",
              " 'lang',\n",
              " 'lang_',\n",
              " 'mem',\n",
              " 'merge',\n",
              " 'noun_chunks',\n",
              " 'noun_chunks_iterator',\n",
              " 'print_tree',\n",
              " 'remove_extension',\n",
              " 'retokenize',\n",
              " 'sentiment',\n",
              " 'sents',\n",
              " 'set_extension',\n",
              " 'similarity',\n",
              " 'tensor',\n",
              " 'text',\n",
              " 'text_with_ws',\n",
              " 'to_array',\n",
              " 'to_bytes',\n",
              " 'to_disk',\n",
              " 'to_json',\n",
              " 'to_utf8_array',\n",
              " 'user_data',\n",
              " 'user_hooks',\n",
              " 'user_span_hooks',\n",
              " 'user_token_hooks',\n",
              " 'vector',\n",
              " 'vector_norm',\n",
              " 'vocab']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "[prop for prop in dir(spacy.tokens.doc.Doc) if not prop.startswith('_')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AaAaip6QmLlp",
        "outputId": "365f161c-32b3-46cf-9c7b-69e8dfe9d4e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'La gata de Juan es muy bonita.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "doc.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6bJoKB6mLlq"
      },
      "source": [
        "## Exploramos el documento\n",
        "\n",
        "Al analizar un texto, spaCy lo divide en una lista de `tokens`, que se acceden iterando sobre el objeto `Doc`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iApFadlzmLlq"
      },
      "outputs": [],
      "source": [
        "[t for t in doc]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6voVaR4mLlr"
      },
      "source": [
        "Esta división es distinta de la simple división por espacios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UTDk6HmmLlr"
      },
      "outputs": [],
      "source": [
        "texto.split(' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkpI_RAemLls"
      },
      "outputs": [],
      "source": [
        "type(doc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU2BiysUmLls"
      },
      "source": [
        "Cada token tiene una serie de atributos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAgXwn84mLls"
      },
      "outputs": [],
      "source": [
        "print([prop for prop in dir(spacy.tokens.token.Token) if not prop.startswith('_')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skU3Q467mLlt"
      },
      "outputs": [],
      "source": [
        "doc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPOsA216mLlu"
      },
      "outputs": [],
      "source": [
        "doc[0].orth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oydnZm1jmLlu"
      },
      "outputs": [],
      "source": [
        "nlp.vocab[\"La\"].orth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOtgyB4UmLlv"
      },
      "outputs": [],
      "source": [
        "doc[0].is_ascii"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9qk3TUImLlv"
      },
      "outputs": [],
      "source": [
        "nlp.vocab[\"La\"].is_ascii"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MSEeDn4mLlw"
      },
      "outputs": [],
      "source": [
        "doc[0].tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4Y8ppWdmLlw"
      },
      "outputs": [],
      "source": [
        "doc[0].tag_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg0iCQRzmLlw"
      },
      "source": [
        "Cada propiedad tiene dos atributos:  \n",
        "- `propiedad`: ID único o *hash* que identifica el valor en un diccionario común a todos los Docs (`stringstore`)\n",
        "- `propiedad_`: valor de la propiedad  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jWOaimRmLlx"
      },
      "outputs": [],
      "source": [
        "nlp.vocab.strings[doc[0].tag]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCdLEiqsmLlx"
      },
      "source": [
        "Veamos los atributos de algunos de los tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxnmZ4gGmLlx"
      },
      "outputs": [],
      "source": [
        "token=doc[3]\n",
        "print(\"TOKEN:\", token)\n",
        "print(\"original:\", token.orth, token.orth_)\n",
        "print(\"lowercased:\", token.lower, token.lower_)\n",
        "print(\"lemma:\", token.lemma, token.lemma_)\n",
        "print(\"shape:\", token.shape, token.shape_)\n",
        "print(\"prefix:\", token.prefix, token.prefix_)\n",
        "print(\"suffix:\", token.suffix, token.suffix_)\n",
        "print(\"log probability:\", token.prob)\n",
        "print(\"Brown cluster id:\", token.cluster)\n",
        "print(\"POS:\", token.pos, token.pos_)\n",
        "print(\"tag:\", token.tag, token.tag_)\n",
        "print(\"morphology:\", token.morph)\n",
        "print(\"Dependency parsing:\", token.dep, token.dep_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmGy7x_XmLly"
      },
      "source": [
        "Las propiedades más importantes son (https://spacy.io/api/token#attributes):  \n",
        "* `orth_`: texto del token\n",
        "* `lemma_`: lema (palabra base)\n",
        "* `shape_`: forma ortográfica del token\n",
        "* `pos_`: Part-of-Speech (genérico)\n",
        "* `tag_`: POS detallado\n",
        "* `morph`: Análisis morfológico\n",
        "* `dep_`: Tipo de dependencia del token (análisis de dependencias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGGIFBMfmLlz"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "datos = map(lambda t: {'token': t.orth_,\n",
        "                       'lema': t.lemma_,\n",
        "                       'shape': t.shape_,\n",
        "                       'POS': t.pos_,\n",
        "                       'TAG': t.tag_,\n",
        "                       'Descripción TAG': spacy.explain(t.tag_),\n",
        "                       'dependencia': t.dep_,\n",
        "                       'Descripción dep': spacy.explain(t.dep_),\n",
        "                       'Morfología': t.morph}, doc)\n",
        "\n",
        "pd.DataFrame(datos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfk_8dsrmLl0"
      },
      "source": [
        "### Diferencia entre token y lexema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLekr2G6mLl0"
      },
      "outputs": [],
      "source": [
        "nlp_en = spacy.load('en_core_web_md')\n",
        "parsedData = nlp_en(\"I run a long run\")\n",
        "datos = map(lambda t: {'token': t.orth_,\n",
        "                       'lema': t.lemma_,\n",
        "                       'shape': t.shape_,\n",
        "                       'POS': t.pos_,\n",
        "                       'Morfología': t.morph,\n",
        "                       'dependencia': t.dep_,\n",
        "                       'Descripción dep': spacy.explain(t.dep_)},\n",
        "                        parsedData)\n",
        "\n",
        "pd.DataFrame(datos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yot6PKsOmLl1"
      },
      "outputs": [],
      "source": [
        "parsedData[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdAq8ib9mLl2"
      },
      "outputs": [],
      "source": [
        "parsedData[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-JuGuFomLl2"
      },
      "outputs": [],
      "source": [
        "parsedData[1]==parsedData[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7t0fEO7mLl2"
      },
      "outputs": [],
      "source": [
        "parsedData[1].orth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqaKDCWNmLl3"
      },
      "outputs": [],
      "source": [
        "nlp.vocab.strings[parsedData[1].orth]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zi6wzzomLl3"
      },
      "outputs": [],
      "source": [
        "parsedData[1].orth==parsedData[4].orth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3tmKNFWmLl4"
      },
      "source": [
        "## Análisis gramatical\n",
        "Los documentos SpaCy también dividen en texto en oraciones (*sentences*) que son objetos del tipo `spacy.tokens.span.Span`. Podemos iterar con el generador `doc.sents` usando `next()`, `list()`, un bucle o con una comprensión de lista."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It6cVrJYmLl4"
      },
      "outputs": [],
      "source": [
        "texto = \"Al Sr. Daniel siempre le gustaron las catedrales. La de su ciudad era tan alta, \\\n",
        "que al mirarla desde su pequeña estatura, tenía que torcer el cuello de tal forma que \\\n",
        "le costaba no marearse. Lo que más temía era que sus pies se despegasen de la tierra \\\n",
        "y la Catedral le arrastrara con ella hasta los cielos. Aun así, un espíritu \\\n",
        "aventurero le llevaba cada tarde hasta la Plaza Mayor.\"\n",
        "doc = nlp(texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3F0cynXmLl5"
      },
      "outputs": [],
      "source": [
        "doc.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch5XQHNymLl5"
      },
      "outputs": [],
      "source": [
        "frases = doc.sents\n",
        "frases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv5x7mwMmLl5"
      },
      "outputs": [],
      "source": [
        "next(frases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVuVdkmhmLl6"
      },
      "outputs": [],
      "source": [
        "type(next(doc.sents))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QgpESeimLl6"
      },
      "outputs": [],
      "source": [
        "for i, sent in enumerate(doc.sents):\n",
        "    print(\"Oración {}:\\n{}\\n\".format(i,sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEt0fRuBmLl7"
      },
      "source": [
        "Cada sentencia también tiene sus propios atributos, distintos de los de los tokens. Para spaCy las oraciones son objetos de tipo `spacy.tokens.span.Span`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbDtHipGmLl7"
      },
      "outputs": [],
      "source": [
        "print([prop for prop in dir(spacy.tokens.span.Span) if not prop.startswith('_')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "891SakSBmLl7"
      },
      "source": [
        "Algunas propiedades de `Span` son distintas que las de cada `Token`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCPOlnzEmLl8"
      },
      "outputs": [],
      "source": [
        "[prop for prop in dir(spacy.tokens.span.Span) if\n",
        " not prop.startswith('_') and not prop in dir(spacy.tokens.token.Token)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBz0v9dsmLl8"
      },
      "outputs": [],
      "source": [
        "frase=next(doc.sents)\n",
        "frase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-EfMKG3mLl8"
      },
      "outputs": [],
      "source": [
        "[t for t in doc[frase.start:frase.end]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6Qy0n5lmLl9"
      },
      "source": [
        "### Ejercicio 1\n",
        "Obtén la palabra raíz -atributo `root`- de cada oración del texto anterior y muéstrala.  \n",
        "La respuesta es  \n",
        "```python  \n",
        "[gustaron, alta, era, llevaba]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhWJLkdRmLl9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koFhvLXbmLl9"
      },
      "source": [
        "### Part of Speech (POS)\n",
        "La librería `spaCy` determina el tipo gramatical (POS) de cada palabra en nuestro texto. Creamos un diccionario con los distintos POS de nuestro texto de ejemplo, usando el *hash* de cada POS como clave del diccionario:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYULSwJcmLl-"
      },
      "outputs": [],
      "source": [
        "{w.pos: (w.pos_, spacy.explain(w.pos_)) for w in doc} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1bbNyDLmLl-"
      },
      "source": [
        "Cada tipo gramatical (POS) se subdivide en distintas etiquetas según su análisis mnorfológico(atributo `morph`).  \n",
        "Por ejemplo en nuestro texto tenemos los siguientes `tag`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBwOX9jzmLl-"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(set([(w.pos_, w.morph) for w in doc]), columns=['POS', 'morph']).sort_values(by='POS')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uncF3aVpmLl_"
      },
      "source": [
        "### Ejercicio 2\n",
        "Crea una lista de Python con todas las palabras del texto `doc` que sean del tipo NOMBRE y además sean de género Femenino.  \n",
        "Ayuda: tendrás que usar una comprensión de lista filtrando mediante una función de búsqueda de texto (o patrón regular) sobre el valor del atributo `morph` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxlgvbsFmLl_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHS3kt87mLl_"
      },
      "source": [
        "### Análisis de dependencias (dependency parsing)\n",
        "La librería `spaCy` también analiza las relaciones entre palabras de una frase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ00au5NmLmA"
      },
      "outputs": [],
      "source": [
        "doc = nlp(\"El perro de Juan se comió mi bocadillo.\")\n",
        "dependencias = [(t.text, t.dep_, spacy.explain(t.dep_)) for t in doc]\n",
        "pd.DataFrame(list(dependencias), columns=['texto', 'dependencia', 'explicación'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZMEUCP2mLmA"
      },
      "outputs": [],
      "source": [
        "doc[0].head"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiBTH2HLmLmB"
      },
      "source": [
        "Cada palabra tiene un tipo de dependencia determinado dentro de la frase. \n",
        "La lista completa está en https://spacy.io/docs/api/annotation  \n",
        "La dependencia `root` coincide con el atributo `root` de cada sentencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT95sEVDmLmB"
      },
      "outputs": [],
      "source": [
        "sent=next(doc.sents)\n",
        "sent.root"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZltRt_Q3mLmB"
      },
      "source": [
        "Cada raíz tiene una serie de hijos (tokens que dependen gramaticalmente de esa raíz)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajp2cjxQmLmC"
      },
      "outputs": [],
      "source": [
        "list(sent.root.children)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfiPYijfmLmC"
      },
      "source": [
        "Podemos extender el análisis a cada palabra del texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIUDiVVcmLmC"
      },
      "outputs": [],
      "source": [
        "for word in sent: \n",
        "    print(word, ': ', str(list(word.children)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHwE6EL7mLmD"
      },
      "source": [
        "Además, cada palabra tiene una palabra de la que depende (`.head`) y unas palabras que dependen de ella (`children`) a izquierda (`.lefts`) y a derecha (`.rights`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXP95kPzmLmD"
      },
      "outputs": [],
      "source": [
        "dependencias = map(lambda t: {\n",
        "    'Palabra': t.orth_,\n",
        "    'tipo de dependencia': f\"{t.dep_} ({spacy.explain(t.dep_)})\",\n",
        "    'HEAD': t.head.orth_},\n",
        "    doc)\n",
        "\n",
        "pd.DataFrame(dependencias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOsy-HNZmLmE"
      },
      "outputs": [],
      "source": [
        "dependencias = map(lambda token: {\n",
        "    'dep. izquierdas': [t.orth_ for t in token.lefts],\n",
        "    'palabra[tipo de dependencia]': f\"{token.orth_} [{token.dep_}]\",\n",
        "    'dep.derechas': [t.orth_ for t in token.rights]},\n",
        "    doc)\n",
        "\n",
        "pd.DataFrame(dependencias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iuHgs_WmLmE"
      },
      "source": [
        "Podemos representar gráficamente las dependencias con el módulo de visualización `displaCy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaGvA2NvmLmF"
      },
      "outputs": [],
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style='dep', jupyter=True, options={'distance':120})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1JGnU5LmLmF"
      },
      "source": [
        "También se pueden obtener los **sintagmas nominales** (*noun phrases*) de la oración. Cada NP tiene un sustantivo como raíz, acompañado ocasionalmente de las palabras que describen el sustantivo.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL4eLW6jmLmG"
      },
      "outputs": [],
      "source": [
        "chunks = map(lambda chunk: {'NP': chunk.text,\n",
        "                            'root': chunk.root.text,\n",
        "                            'Dep.': chunk.root.dep_,\n",
        "                            'head': chunk.root.head.text},\n",
        "             doc.noun_chunks)\n",
        "\n",
        "pd.DataFrame(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdgmOHZvmLmG"
      },
      "source": [
        "# Búsqueda de patrones\n",
        "Spacy tiene una clase `Matcher` que permite buscar tokens con un patrón definido en los objetos `Doc`.  \n",
        "Se puede buscar por el texto del token o por los atributos del token.  \n",
        "Ref: https://spacy.io/usage/rule-based-matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0A7uFSOmLmG"
      },
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "#inicializamos sobre el vocabulario\n",
        "matcher = Matcher(nlp.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2_US7aGmLmH"
      },
      "outputs": [],
      "source": [
        "#definimos un patrón de texto a buscar\n",
        "patron = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}] #Patrón: texto 'iPhone' seguido de texto 'X'\n",
        "matcher.add(\"iphone_x\", [patron])\n",
        "\n",
        "#procesamos un documento con el patrón\n",
        "doc = nlp(\"El iPhone X salió después del iPhone 8, pero nunca sacaron el iPhone 9\")\n",
        "\n",
        "#llamamos al matcher\n",
        "matches = matcher(doc)\n",
        "\n",
        "#iteramos sobre los resultados\n",
        "for match_id, start, end in matches:\n",
        "    matched_span = doc[start:end]\n",
        "    print(matched_span.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF6P1w4vmLmH"
      },
      "outputs": [],
      "source": [
        "matches #lista de 'matches'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQPp31XwmLmI"
      },
      "outputs": [],
      "source": [
        "nlp.vocab.strings[1738708750870670527]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnFgKfe_mLmI"
      },
      "source": [
        "Podemos buscar por atributos del token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsABw2CWmLmI"
      },
      "outputs": [],
      "source": [
        "patron = [{\"TEXT\": \"iPhone\"}, {\"IS_DIGIT\": True}] #Patrón: texto 'iPhone' seguido token con la atributo 'IS_DIGIT' a True\n",
        "matcher.add(\"iphone_NN\", [patron])\n",
        "#llamamos al matcher\n",
        "matches = matcher(doc)\n",
        "\n",
        "#iteramos sobre los resultados\n",
        "for match_id, start, end in matches:\n",
        "    matched_span = doc[start:end] #span del match en el documento\n",
        "    string_id = nlp.vocab.strings[match_id] #identificador del match\n",
        "    print(f\"{string_id}: {matched_span.text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9WH7Wm_mLmJ"
      },
      "outputs": [],
      "source": [
        "doc = nlp(\"A mí me gusta el baile y a Pedro le gustaba tocar la trompeta pero no le gusta María y le gusta el iPhone X\")\n",
        "\n",
        "patron = [{\"LEMMA\": \"gustar\"}, {\"POS\": \"PROPN\"}]\n",
        "matcher.add(\"gustar_persona\", [patron])\n",
        "#llamamos al matcher\n",
        "matches = matcher(doc)\n",
        "\n",
        "#iteramos sobre el resultado\n",
        "for match_id, start, end in matches:\n",
        "    matched_span = doc[start:end]\n",
        "    string_id = nlp.vocab.strings[match_id]\n",
        "    print(f\"{string_id}: {matched_span.text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOSIfHEamLmJ"
      },
      "outputs": [],
      "source": [
        "doc = nlp(\"A mí me gusta el baile y a Pedro le gustaba tocar la trompeta pero no le gusta María y el gusta el iPhone X\")\n",
        "\n",
        "patron = [{\"LEMMA\": \"gustar\"}, {\"POS\": \"DET\", \"OP\": \"?\"}, {\"POS\": {\"REGEX\": \"NOUN|PROPN\"}}]\n",
        "matcher.add(\"gustar_nombre\", [patron])\n",
        "#llamamos al matcher\n",
        "matches = matcher(doc)\n",
        "\n",
        "#iteramos sobre el resultado\n",
        "for match_id, start, end in matches:\n",
        "    matched_span = doc[start:end]\n",
        "    string_id = nlp.vocab.strings[match_id]\n",
        "    print(f\"{string_id}: {matched_span.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1bdq7GDmLmK"
      },
      "source": [
        "### Ejercicio 3\n",
        "Crea un nuevo patrón para el lema \"gustar\" seguido de un verbo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZPqQhgqmLmK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A80WAtxmLmK"
      },
      "source": [
        "### Ejercicio 4\n",
        "Busca todas las secuencias de texto formadas por nombre seguido de al menos un adjetivo en el texto siguiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rfpw7JnFmLmL"
      },
      "outputs": [],
      "source": [
        "texto = \"En el agua muerta, de una brillantez de estaño, permanecía inmóvil la barca-correo: \\\n",
        "un gran ataúd cargado de personas y paquetes, con la borda casi a flor de agua. La vela triangular, \\\n",
        "con remiendos obscuros, estaba rematada por un guiñapo incoloro que en otros tiempos había sido una \\\n",
        "bandera española rota y delataba el carácter oficial de la vieja embarcación.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSDNSFFumLmL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "colab": {
      "name": "NLP_04-Introducción al spaCy.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}